{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook served to explore 3 purposes:\n",
    "\n",
    "- Tensorboard integration for training.\n",
    "- Autotransform generation with PyTorch Image Models (`timm`).\n",
    "- Model inference with raw image (`.jpg`, `.png`, etc.) with `timm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import setup_data, utils, plot, engine\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will get autotransformation from the model, so the model determines the transformations passed to DataLoader, hence the model is the first thing to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_a1',\n",
       " 'mnasnet_b1',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'SelecSls42',\n",
       " 'SelecSls42b',\n",
       " 'SelecSls60',\n",
       " 'SelecSls60b',\n",
       " 'SelecSls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26tn_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch16_xp_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_clip_224',\n",
       " 'vit_base_patch32_clip_384',\n",
       " 'vit_base_patch32_clip_448',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_clip_224',\n",
       " 'vit_giant_patch14_dinov2',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_gigantic_patch14_clip_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_clip_224',\n",
       " 'vit_huge_patch14_clip_336',\n",
       " 'vit_huge_patch14_xp_224',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_clip_224',\n",
       " 'vit_large_patch14_clip_336',\n",
       " 'vit_large_patch14_dinov2',\n",
       " 'vit_large_patch14_xp_224',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_medium_patch16_gap_240',\n",
       " 'vit_medium_patch16_gap_256',\n",
       " 'vit_medium_patch16_gap_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224',\n",
       " 'vit_small_patch14_dinov2',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_384',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_384',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_384',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_384',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_384',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_384',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_384',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_384',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_384',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_384',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_384',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_384',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_384',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_384']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try BeiT V2 - the model was mentioned in one of The Batch issue with good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cb0494/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=235, interpolation=bicubic, max_size=None, antialias=warn)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    ToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('beitv2_large_patch16_224', pretrained=True, num_classes=101).to(device)\n",
    "# Okay, it was stupid - I still need to number of classes to initialize the model.\n",
    "data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
    "transform = timm.data.create_transform(**data_cfg)\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape                              Output Shape                             Param #                                  Trainable\n",
       "========================================================================================================================================================================================================\n",
       "Beit (Beit)                              [32, 3, 224, 224]                        [32, 101]                                1,024                                    True\n",
       "├─PatchEmbed (patch_embed)               [32, 3, 224, 224]                        [32, 196, 1024]                          --                                       True\n",
       "│    └─Conv2d (proj)                     [32, 3, 224, 224]                        [32, 1024, 14, 14]                       787,456                                  True\n",
       "│    └─Identity (norm)                   [32, 196, 1024]                          [32, 196, 1024]                          --                                       --\n",
       "├─Dropout (pos_drop)                     [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "├─ModuleList (blocks)                    --                                       --                                       --                                       True\n",
       "│    └─Block (0)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (1)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (2)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (3)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (4)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (5)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (6)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (7)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (8)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (9)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (10)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (11)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (12)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (13)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (14)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (15)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (16)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (17)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (18)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (19)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (20)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (21)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (22)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (23)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          4,209,088                                True\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    True\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          8,393,728                                True\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "├─Identity (norm)                        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "├─LayerNorm (fc_norm)                    [32, 1024]                               [32, 1024]                               2,048                                    True\n",
       "├─Dropout (head_drop)                    [32, 1024]                               [32, 1024]                               --                                       --\n",
       "├─Linear (head)                          [32, 1024]                               [32, 101]                                103,525                                  True\n",
       "========================================================================================================================================================================================================\n",
       "Total params: 303,509,093\n",
       "Trainable params: 303,509,093\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 12.20\n",
       "========================================================================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 9967.00\n",
       "Params size (MB): 910.52\n",
       "Estimated Total Size (MB): 10896.80\n",
       "========================================================================================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=40,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0msetup_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtest_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Returns the data loaders for training, validation, and testing.\n",
      "\n",
      "Args:\n",
      "    batch_size (int): Batch size for the data loaders\n",
      "    \n",
      "Returns:\n",
      "    train_loader (torch.utils.data.DataLoader): Data loader for training data\n",
      "    valid_loader (torch.utils.data.DataLoader): Data loader for validation data\n",
      "    test_loader (torch.utils.data.DataLoader): Data loader for testing data\n",
      "    test_data (torchvision.datasets.ImageFolder): Testing data\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mget_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Returns the data loaders for training, validation, and testing.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m        batch_size (int): Batch size for the data loaders\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m        train_loader (torch.utils.data.DataLoader): Data loader for training data\u001b[0m\n",
      "\u001b[0;34m        valid_loader (torch.utils.data.DataLoader): Data loader for validation data\u001b[0m\n",
      "\u001b[0;34m        test_loader (torch.utils.data.DataLoader): Data loader for testing data\u001b[0m\n",
      "\u001b[0;34m        test_data (torchvision.datasets.ImageFolder): Testing data\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Nutri-2.0/helper/setup_data.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "setup_data.get_data_loaders??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, test_data = setup_data.get_data_loaders(transform, transform, batch_size=32)\n",
    "classes, class_to_idx, idx_to_class = setup_data.get_metadata(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.blocks.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape                              Output Shape                             Param #                                  Trainable\n",
       "========================================================================================================================================================================================================\n",
       "Beit (Beit)                              [32, 3, 224, 224]                        [32, 101]                                1,024                                    Partial\n",
       "├─PatchEmbed (patch_embed)               [32, 3, 224, 224]                        [32, 196, 1024]                          --                                       True\n",
       "│    └─Conv2d (proj)                     [32, 3, 224, 224]                        [32, 1024, 14, 14]                       787,456                                  True\n",
       "│    └─Identity (norm)                   [32, 196, 1024]                          [32, 196, 1024]                          --                                       --\n",
       "├─Dropout (pos_drop)                     [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "├─ModuleList (blocks)                    --                                       --                                       --                                       False\n",
       "│    └─Block (0)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (1)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (2)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (3)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (4)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (5)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (6)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (7)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (8)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (9)                         [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (10)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (11)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (12)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (13)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (14)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (15)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (16)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (17)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (18)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (19)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (20)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (21)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (22)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    └─Block (23)                        [32, 197, 1024]                          [32, 197, 1024]                          2,048                                    False\n",
       "│    │    └─LayerNorm (norm1)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Attention (attn)             [32, 197, 1024]                          [32, 197, 1024]                          (4,209,088)                              False\n",
       "│    │    └─Identity (drop_path1)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "│    │    └─LayerNorm (norm2)            [32, 197, 1024]                          [32, 197, 1024]                          (2,048)                                  False\n",
       "│    │    └─Mlp (mlp)                    [32, 197, 1024]                          [32, 197, 1024]                          (8,393,728)                              False\n",
       "│    │    └─Identity (drop_path2)        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "├─Identity (norm)                        [32, 197, 1024]                          [32, 197, 1024]                          --                                       --\n",
       "├─LayerNorm (fc_norm)                    [32, 1024]                               [32, 1024]                               2,048                                    True\n",
       "├─Dropout (head_drop)                    [32, 1024]                               [32, 1024]                               --                                       --\n",
       "├─Linear (head)                          [32, 1024]                               [32, 101]                                103,525                                  True\n",
       "========================================================================================================================================================================================================\n",
       "Total params: 303,509,093\n",
       "Trainable params: 894,053\n",
       "Non-trainable params: 302,615,040\n",
       "Total mult-adds (Units.GIGABYTES): 12.20\n",
       "========================================================================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 9967.00\n",
       "Params size (MB): 910.52\n",
       "Estimated Total Size (MB): 10896.80\n",
       "========================================================================================================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=40,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "accuracy_fn = torchmetrics.Accuracy(task='multiclass', num_classes=len(classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train` function needs to be modified to support Tensorboard logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_loader: torch.utils.data.DataLoader,\n",
    "          valid_loader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "          accuracy_fn: torchmetrics.Accuracy,\n",
    "          device: torch.device,\n",
    "          epochs: int,\n",
    "          threshold: List[float]) -> Dict[str, List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Trains the model and evaluates it on the validation set.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): Model to be trained\n",
    "        train_loader (torch.utils.data.DataLoader): Training data loader\n",
    "        valid_loader (torch.utils.data.DataLoader): Validation data loader\n",
    "        loss_fn (torch.nn.Module): Loss function\n",
    "        optimizer (torch.optim.Optimizer): Optimizer\n",
    "        scheduler (torch.optim.lr_scheduler.LRScheduler): Learning rate scheduler\n",
    "        accuracy_fn (torchmetrics.Accuracy): Accuracy function\n",
    "        device (torch.device): Device to run the training on\n",
    "        epochs (int): Number of epochs to train the model for\n",
    "        threshold (float): Threshold for early stopping\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing training and validation losses and accuracies for each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "        For example if training for epochs=2: \n",
    "                    {train_loss: [2.0616, 1.0537],\n",
    "                    train_acc: [0.3945, 0.3945],\n",
    "                    test_loss: [1.2641, 1.5706],\n",
    "                    test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    results = {\"train_losses\": [], \"train_accuracies\": [],\n",
    "               \"valid_losses\": [], \"valid_accuracies\": []}\n",
    "    \n",
    "    tolerance = 0\n",
    "    threshold = torch.Tensor(threshold)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = engine.train_step(model, train_loader, loss_fn, optimizer, scheduler, accuracy_fn, device)\n",
    "        valid_loss, valid_acc = engine.test_step(model, valid_loader, loss_fn, accuracy_fn, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} of {epochs}\"\n",
    "            f\"\\n-------------------------------\"\n",
    "        )\n",
    "\n",
    "        results[\"train_losses\"].append(train_loss.detach())\n",
    "        results[\"train_accuracies\"].append(train_acc.cpu())\n",
    "        results[\"valid_losses\"].append(valid_loss.detach())\n",
    "        results[\"valid_accuracies\"].append(valid_acc.cpu())\n",
    "        if len(results[\"valid_losses\"]) > 1 and results[\"valid_losses\"][-2] - results[\"valid_losses\"][-1] < threshold:\n",
    "            tolerance += 1\n",
    "            if tolerance > 2:\n",
    "                break\n",
    "        # Add loss results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Loss\", \n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"valid_loss\": valid_loss},\n",
    "                           global_step=epoch)\n",
    "\n",
    "        # Add accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"valid_acc\": valid_acc}, \n",
    "                           global_step=epoch)\n",
    "        \n",
    "        # Track the PyTorch model architecture\n",
    "        writer.add_graph(model=model, \n",
    "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "    \n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "    \n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used VSCode to run Tensorboard. However, after the first launch, Tensorboard cannot be launched again. This is an artifact of the plugin. To fix this, I need to kill the process manually and launch Tensorboard from CLI. This [answer](https://stackoverflow.com/a/68119251) helped me to reach this. I also needed to install `lsof` to get the process ID and use `kill` to kill the process. The process can be found [here](https://landoflinux.com/linux_lsof_command_examples.html) and [here](https://linuxhandbook.com/kill-process-port/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b909262131483e926804de733342be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd0420b4f264415b3b683cec39069a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model::   0%|          | 0/2218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.20150 | Train accuracy: 0.70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c5f96ae9174b74bd3dafb0957bfa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions::   0%|          | 0/1038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.60373 | Test accuracy: 0.83\n",
      "Epoch 1 of 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cb0494/lib/python3.11/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f1296b4b5a48c19909839b31790539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model::   0%|          | 0/2218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.74406 | Train accuracy: 0.80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a3c8ba075049d59d589738d2236990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions::   0%|          | 0/1038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.48520 | Test accuracy: 0.87\n",
      "Epoch 2 of 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26caa135b2394d52b7fb0df1cec2cddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model::   0%|          | 0/2218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.56183 | Train accuracy: 0.84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991d2203fefc4df5a20c1deef9538f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions::   0%|          | 0/1038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.43722 | Test accuracy: 0.88\n",
      "Epoch 3 of 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a63498f4cf44fcfa245637c90d15ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model::   0%|          | 0/2218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.49756 | Train accuracy: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1bce91f1b442b1b755082b83d7ce40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions::   0%|          | 0/1038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.44402 | Test accuracy: 0.87\n",
      "Epoch 4 of 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877d1be224e240a2a3370bd3c5a61a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model::   0%|          | 0/2218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.52504 | Train accuracy: 0.85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260aa3bfddf9409e8da6ec14a6712c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions::   0%|          | 0/1038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.77162 | Test accuracy: 0.79\n",
      "Epoch 5 of 5\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = train(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                loss_fn,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                accuracy_fn,\n",
    "                device,\n",
    "                EPOCHS,\n",
    "                threshold=[1e-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished training! As you can see, OneCycleLR from SuperConvergence is amazing - I could get very near to 90% accuracy in just 3 epochs - that's SuperConvergence. However, it is also aggressive: the accuracy on test set start to drop after 3 epochs. It is a great scheduler at first, but after 3-4 epochs the model will benefit from a more conservative scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I nearly forgot: the visualization of the metrics inside Tensorboard can be found [here](https://tensorboard.dev/experiment/WVRhweDbRdKs3WnTEIL34w/) or at this link: https://tensorboard.dev/experiment/WVRhweDbRdKs3WnTEIL34w/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = engine.test_step(model, test_loader, loss_fn, accuracy_fn, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb0494",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
